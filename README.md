# DSCI-560-Lab3
By the end of this lab, you will be able to: 
1. Write and execute a C program performing large matrix operations on a CPU. 
2. Measure CPU execution performance with different matrix sizes. 
3. Port the program to CUDA and execute it on a GPU. 
4. Deploy a GPU-enabled virtual machine on Google Cloud and run CUDA programs. 
5. Optimize CUDA code for better GPU performance. 
6. Compare performance results between CPU, na√Øve CUDA, optimized CUDA, and 
cuBLAS implementations. 
7. Analyze performance scaling as the problem size grows. 
8. Create shared libraries using CUDA and make use of the acceleration from Python.
